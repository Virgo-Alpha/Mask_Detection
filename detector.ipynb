{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this tutorial: https://zindi.africa/learn/spot-the-mask-challenge-tutorial-a-deep-learning-approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a deep learning framework built for Python which provides methods to train deep learning models. Keras has built-in support for CNNs (for computer vision) and has a user-friendly API that makes it easy to quickly prototype deep learning models.\n",
    "\n",
    "Importing the sequential method, means that all the layers in the model will be arranged in sequence. The importance of ImageDataGenerator is to generate batches of tensor image data with real-time data augmentation. It has very many useful functions such as rescaling, rotating, zooming etc.\n",
    "\n",
    "The keras.layers import gives us access to layers that we need to build our CNN which are described above. Layers are the building blocks of neural networks.\n",
    "\n",
    "Optimizers are necessary for improving your model speed and performance. Optimizers shape the model into its most accurate form by playing with model weights.\n",
    "\n",
    "VGG16 is a convolutional neural network architecture which provides 16 layers. Its a pretrained model. VGG16 is a model employs the transfer learning architecture. Transfer learning is the art of reusing a model on one task and repurposing it on another task.\n",
    "\n",
    "Pandas library provides built-in methods for data manipulation.\n",
    "\n",
    "Matplotlib is used for creating graphs where necessary when building our model.\n",
    "\n",
    "The IPython.display imports a method for viewing images within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import Image as ShowImage\n",
    "# Keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization,GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "train_labels = pd.read_csv(\"data/train_labels.csv\")\n",
    "# Show the first 5 rows\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['target'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts all the files\n",
    "!unzip -q images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can view the images with the ShowImage functionality\n",
    "ShowImage(\"/content/images/aadawlxbmapqrblgxyzarhjasgiobu.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you found this fun, you can also use the OpenCV Library to view images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import os\n",
    "\n",
    "# This stores the location of the data source\n",
    "data = os.listdir(\"images\")\n",
    "\n",
    "# Picking random sample from data list\n",
    "sample = random.choice(data)\n",
    "\n",
    "# The imread method loads image from the sprcified file\n",
    "img = cv2.imread(\"images/\"+sample)\n",
    "\n",
    "# The cmap parameter displays the image in gray\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample_submission.csv\n",
    "\n",
    "This is the file that is used for making submissions after you have created your model.\n",
    "\n",
    "We should replace the target variables (0,1) into categories (mask, unmask) using the replace method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[\"target\"] = train_labels[\"target\"].replace({0: 'unmask', 1: 'mask'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the CNN\n",
    "\n",
    "First, we need to declare how the image data will be passed to the input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining how data is passed to the input layer\n",
    "image_size = 224\n",
    "input_shape = (image_size, image_size, 3)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, convnets take input tensors of the shape - image height, image width and image channels. The imagesâ€™ input shape from the code above is (224,224,3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
    "for layer in pre_trained_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in pre_trained_model.layers[15:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('block5_pool')\n",
    "last_output = last_layer.output\n",
    "x = GlobalMaxPooling2D()(last_output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(pre_trained_model.input, x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are passing our parameters on to our VGG16.\n",
    "\n",
    "The include_top parameter states whether to include the output layers or not. In case you are fitting your model into your own problem, you don't need it.\n",
    "\n",
    "The weights parameter specifies what weights to load.\n",
    "\n",
    "GlobalMaxPooling2D - this is another pooling type where the pooling size is set to equal the input size, so that the max of the entire input is connected as the output value.\n",
    "\n",
    "Dense implements the operation using the ReLU and Softmax algorithm respectively.\n",
    "\n",
    "The model compile method defines the model by specifying the optimiser, loss and metrics.\n",
    "\n",
    "The loss parameter is specified to type 'binary_crossentropy'. This measures how the network will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
    "\n",
    "An optimiser is the mechanism through which the network will update itself based on the data it sees and its loss function. The metrics parameter is set to 'accuracy' - here we only care about how the model will perform.\n",
    "\n",
    "The optimiser is set to Stochastic Gradient Descent Optimiser. This refers to the mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "\n",
    "The model summary method is used to see all parameters and shapes in each layers in our models, which will give you the following result:\n",
    "\n",
    "```\n",
    "The total parameters are 14,978,370\n",
    "\n",
    "The trainable parameters are 7,343,106\n",
    "\n",
    "The non-trainable parameters are 7,635,264\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',patience=2,verbose=1,factor=0.5,min_lr=0.00001)\n",
    "callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlystop is a technique that is used to reduce overfitting without comprising on model accuracy. Too many epochs can lead to overfitting, hence the need to apply the technique.\n",
    "\n",
    "An epoch means training the network with all the training data for one cycle. A forward pass and a backward pass are counted as one pass.\n",
    "\n",
    "ReduceLROnPlateau is a callback to reduce the learning rate when a metric has stopped improving.\n",
    "\n",
    "Patience is the number of epochs with no improvement after which the learning rate is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df,validate_df=train_test_split(train_labels,test_size=0.2,random_state=42)\n",
    "train_df = train_df.reset_index(drop='True')\n",
    "validate_df = validate_df.reset_index(drop='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are importing the train_test_split method from sklearn that basically splits the training data into two separate dataframes - the training and the testing data. random_state parameter sets the seed to the random generator so that your train-test splits are always deterministic.\n",
    "\n",
    "Next, we need to categorically encode categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "# Categorical encodes categorical variables\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are rescaling the images, applying shear in some ranges, zooming the image and flipping the image horizontally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are formatting the training data\n",
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                 rescale=1./255,\n",
    "                                 shear_range=0.1,\n",
    "                                 zoom_range=0.2, # zoom range (1-0.2 to 1+0.2)\n",
    "                                 horizontal_flip=True,\n",
    "                                 width_shift_range=0.1,\n",
    "                                 height_shift_range=0.1)\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                  directory=\"images/\",\n",
    "                                                  x_col=\"image\",\n",
    "                                                  y_col=\"target\",\n",
    "                                                  target_size=(image_size,image_size),\n",
    "                                                  class_mode='categorical',\n",
    "                                                  batch_size=15)\n",
    "# Here we are formatting images on the validation data\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                  directory=\"images/\",\n",
    "                                                  x_col=\"image\",\n",
    "                                                  y_col=\"target\",\n",
    "                                                  target_size=(image_size,image_size),\n",
    "                                                  class_mode='categorical',\n",
    "                                                  batch_size=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to fit the model into the training data and we are running it for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100 \n",
    "total_validate = validate_df.shape[0]\n",
    "total_train = train_df.shape[0]\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks)\n",
    "    \n",
    "# Here we are creating a list of pictures - we are appending images on the list.\n",
    "# Our data source is the original data before splitting to test and train data\n",
    "target=[]\n",
    "for i in data:\n",
    "    flag=0\n",
    "    for j in df[\"image\"]:\n",
    "        if(i==j):\n",
    "            flag=1\n",
    "            break;\n",
    "        else:\n",
    "            continue\n",
    "    if(flag==0):    \n",
    "       target.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are creating a test data set using the image data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a test dataframe with images and the target is umask for all images\n",
    "test = pd.DataFrame({\n",
    "    'image': target,\n",
    "    'target':\"unmask\"\n",
    "})\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to pass our test data to the image data generator - to fit the model into the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test, \n",
    "    directory=\"images/\", \n",
    "    x_col=\"image\",\n",
    "    y_col=\"target\",\n",
    "    target_size=(image_size,image_size),\n",
    "    class_mode='categorical',\n",
    "    batch_size=15,\n",
    "    shuffle=False)\n",
    "nb_samples = test.shape[0]\n",
    "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.predict_generator helps make predictions on new image data.\n",
    "\n",
    "The np.ceil method is used to find the ceil of the elements of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are converting the submission data to a dataframe\n",
    "test[\"target\"]=predict\n",
    "\n",
    "#here we are converting to a csv file\n",
    "test.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we save our data on the submission file. When submitting the final result, always ensure that its in csv format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
